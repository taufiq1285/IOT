# ğŸŒ¡ï¸ IoT Environmental Monitoring System
## Big Data & Predictive Analytics - Project Mini

**Topik:** Lake vs Warehouse; Batch vs Streaming; Format Data  
**Skenario:** IoT Lingkungan - Smart Lab & Classroom Monitoring  
**Kelompok:** [NAMA KELOMPOK ANDA]

---

## ğŸ“‹ Daftar Anggota

| No | Nama | NIM | Kontribusi |
|----|------|-----|------------|
| 1  | [Taufiq] | | Arsitektur, Data Generation |
| 2  | [aswin] |  | Batch Pipeline, Data Quality |
| 3  | [ahmad fauzan] |  | Streaming Simulation |
| 4  | [Rifki arianto] | | Queries, Benchmark |
| 5  | [herawanti | | Documentation, Laporan |

---

## ğŸ¯ Tujuan Proyek

Membangun sistem monitoring lingkungan IoT untuk optimasi kenyamanan dan efisiensi energi di kampus dengan:
- âœ… Real-time alerts untuk kondisi tidak nyaman
- âœ… Historical analysis untuk optimasi jadwal AC
- âœ… Data-driven decision making

---

## ğŸ—ï¸ Arsitektur Sistem

### High-Level Architecture
![Architecture Diagram](01_architecture/architecture_diagram.md)

### Technology Stack
- **Language:** Python 3.11+
- **Processing:** Pandas, NumPy
- **Formats:** CSV, JSON, Parquet
- **Compression:** Snappy

### Data Pipeline
```
IoT Sensors â†’ Streaming/Batch â†’ Bronze â†’ Silver â†’ Gold â†’ Analytics
              (Raw Data)         (Cleaned)  (Warehouse)  (Insights)
```

---

## ğŸš€ Quick Start (PENTING!)

### Prerequisites
```bash
# Python 3.8+ required
python --version

# VS Code (recommended)
```

### Setup Environment

**Langkah 1: Clone/Download Project**
```bash
# Jika dari Git
git clone [URL_REPO]
cd iot_project

# Atau extract ZIP file
unzip BDPA_TugasProyek_Kelompok[1]_IoT.zip
cd BDPA_TugasProyek_Kelompok[1]_IoT
```

**Langkah 2: Install Dependencies**
```bash
pip install -r requirements.txt
```

**Langkah 3: Run Pipeline (BERURUTAN!)**

```bash
# 1. Generate dataset (3000 records)
python 02_data/generator.py

# 2. Run batch pipeline (Bronze â†’ Silver â†’ Gold)
python 03_pipeline/batch_pipeline.py

# 3. Run streaming simulation (50 events, 5s interval)
python 03_pipeline/streaming_simulation.py

# 4. Execute sample queries
python 04_queries/sample_queries.py

# 5. Run benchmark comparison
python 05_evaluation/benchmark_formats.py
```

**Total execution time: ~5-10 menit**

---

## ğŸ“ Struktur Project

```
BDPA_TugasProyek_Kelompok[1]_IoT/
â”‚
â”œâ”€â”€ 01_architecture/               # Diagram & dokumentasi arsitektur
â”‚   â””â”€â”€ architecture_diagram.md
â”‚
â”œâ”€â”€ 02_data/                       # Data & generator
â”‚   â”œâ”€â”€ generator.py              â† [RUN FIRST!]
â”‚   â”œâ”€â”€ raw/                      # CSV, JSON (row-oriented)
â”‚   â”œâ”€â”€ bronze/                   # Parquet (unified)
â”‚   â”œâ”€â”€ silver/                   # Cleaned data
â”‚   â”œâ”€â”€ gold/                     # Data warehouse (star schema)
â”‚   â””â”€â”€ stream_output/            # Streaming results
â”‚
â”œâ”€â”€ 03_pipeline/                   # ETL pipelines
â”‚   â”œâ”€â”€ batch_pipeline.py         â† [RUN SECOND!]
â”‚   â””â”€â”€ streaming_simulation.py   â† [RUN THIRD!]
â”‚
â”œâ”€â”€ 04_queries/                    # Analytical queries
â”‚   â”œâ”€â”€ sample_queries.py         â† [RUN FOURTH!]
â”‚   â”œâ”€â”€ query1_result.csv
â”‚   â”œâ”€â”€ query2_result.csv
â”‚   â””â”€â”€ query3_result.csv
â”‚
â”œâ”€â”€ 05_evaluation/                 # Benchmark & evaluation
â”‚   â”œâ”€â”€ benchmark_formats.py      â† [RUN FIFTH!]
â”‚   â”œâ”€â”€ benchmark_results.csv
â”‚   â””â”€â”€ format_comparison.png
â”‚
â”œâ”€â”€ 06_docs/                       # Documentation
â”‚   â”œâ”€â”€ data_dictionary.csv
â”‚   â”œâ”€â”€ data_dictionary.md
â”‚   â””â”€â”€ LAPORAN.md               # Template laporan PDF
â”‚
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
```

---

## ğŸ“Š Hasil Evaluasi

### File Size Comparison

| Format | Size | vs CSV | Use Case |
|--------|------|--------|----------|
| CSV | ~2.5 MB | Baseline | Human-readable, debugging |
| JSON | ~3.5 MB | +40% | Streaming, flexible schema |
| **Parquet** | **~0.8 MB** | **-68%** | âœ… **Analytics, production** |

**Kesimpulan:** Parquet menghemat **68% storage** dengan **2-3x faster** reads!

### Query Performance

| Query Type | CSV | Parquet | Speedup |
|------------|-----|---------|---------|
| Full Scan | 150ms | 50ms | **3x faster** |
| Aggregation | 120ms | 40ms | **3x faster** |
| Column Read | 80ms | 15ms | **5x faster** |

---

## ğŸ¯ Design Decisions

### 1ï¸âƒ£ **Lake vs Warehouse: Hybrid Approach**

**Data Lake (Bronze/Silver):**
- âœ… Store raw data for reprocessing
- âœ… Schema flexibility
- âœ… Cost-effective for historical data

**Data Warehouse (Gold):**
- âœ… Optimized star schema
- âœ… Fast analytical queries
- âœ… Pre-aggregated summaries

**Justifikasi:** Hybrid memberikan fleksibilitas (lake) + performance (warehouse)

### 2ï¸âƒ£ **Batch vs Streaming: Lambda Architecture**

**Streaming (Real-time):**
- âœ… Alerts untuk kondisi abnormal
- âœ… Live monitoring
- â±ï¸ Latency: <10 seconds

**Batch (Historical):**
- âœ… Daily aggregations
- âœ… Data quality enforcement
- â±ï¸ Schedule: 1x per day

**Justifikasi:** Lambda memenuhi kebutuhan real-time DAN historical analysis

### 3ï¸âƒ£ **Format Selection**

| Layer | Format | Reasoning |
|-------|--------|-----------|
| Bronze (Raw) | JSON | Preserve original, easy debug |
| Bronze (Unified) | Parquet | Efficient storage |
| Silver | Parquet + Snappy | Compressed, cleaned |
| Gold | Parquet | Columnar for analytics |

---

## ğŸ“ˆ Sample Queries

### Query 1: Average Temperature per Building
```python
df.groupby('building').agg({
    'temperature': ['mean', 'min', 'max']
})
```

### Query 2: High Temperature Rooms (>28Â°C)
```python
high_temp = df[df['temperature'] > 28]
high_temp.groupby('room_id').size()
```

### Query 3: Hourly Trend (Last 24h)
```python
df.groupby(df['timestamp'].dt.floor('H')).agg({
    'temperature': 'mean'
})
```

---

## ğŸ›¡ï¸ Data Quality & Governance

### Data Quality Rules
âœ… No null values in critical fields (timestamp, sensor_id)  
âœ… Temperature range: 15-40Â°C  
âœ… Humidity range: 30-90%  
âœ… CO2 range: 350-3000 ppm  
âœ… Duplicate detection based on (sensor_id, timestamp)

### Metadata Management
- **Data Dictionary:** Complete column definitions
- **Lineage:** Bronze â†’ Silver â†’ Gold tracked
- **Versioning:** Timestamp-based partitioning

### Access Control (Conceptual)
| Role | Bronze | Silver | Gold |
|------|--------|--------|------|
| Data Engineer | Read/Write | Read/Write | Read/Write |
| Analyst | Read | Read | Read |
| Public Dashboard | - | - | Read (aggregated only) |

### Retention Policy
- **Bronze:** 90 days (raw data)
- **Silver:** 1 year (cleaned)
- **Gold:** 3 years (warehouse)

---

## âš ï¸ Risiko & Mitigasi

| Risiko | Dampak | Mitigasi |
|--------|--------|----------|
| Schema berubah | Pipeline break | Use flexible JSON in Bronze, schema validation |
| Data skew | Unbalanced partitions | Monitor partition sizes, repartition if needed |
| Late/dirty data | Quality issues | Implement data validation rules, quarantine bad data |
| Sensor failure | Missing data | Alert on prolonged gaps, use interpolation for short gaps |

---

## ğŸ“ Deliverables Checklist

- [x] Laporan PDF (max 6 halaman)
- [x] Diagram arsitektur (PNG/SVG)
- [x] Kode: Python scripts (.py)
- [x] Dataset: 3000 records, multiple formats
- [x] Data dictionary
- [x] Log kontribusi anggota

---

## ğŸ“ Learning Outcomes (CPMK)

âœ… **Membedakan Data Lake vs Warehouse:** Implemented hybrid approach  
âœ… **Batch vs Streaming:** Lambda architecture with clear SLAs  
âœ… **Format Selection:** Empirical comparison of CSV/JSON/Parquet  
âœ… **End-to-end Pipeline:** Complete Bronze-Silver-Gold pipeline

---

## ğŸ“ Kontak

**Kelompok:** [NAMA KELOMPOK]  
**Email:** [EMAIL]  
**Mata Kuliah:** Big Data & Predictive Analytics  
**Dosen:** [NAMA DOSEN]

---

## ğŸ“œ License

Educational project for academic purposes only.

---

**Terakhir diupdate:** [TANGGAL]
